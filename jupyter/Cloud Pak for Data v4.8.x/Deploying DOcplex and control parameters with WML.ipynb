{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying DOcplex and control parameters with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a DOcplex model and pass environment variables to control the flow control in our Decision Optimization Python script using the Watson Machine Learning Python Client.\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents:**\n",
    "\n",
    "- [Set up the Watson Machine Learning client](#setup)\n",
    "- [Create a client instance](#create)\n",
    "- [Prepare your model archive](#prepare)\n",
    "- [Upload your model on Watson Machine Learning](#upload)\n",
    "- [Create a deployment](#deploy)\n",
    "- [Create and monitor a job for your deployed model](#job)\n",
    "- [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install WML client API\n",
    "\n",
    "!pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "\n",
    "cluster = \"<your_cluster>\"\n",
    "username = \"<username>\"\n",
    "password = \"<password>\"\n",
    "\n",
    "wml_credentials = {\n",
    "    \"username\": username,\n",
    "    \"password\": password,\n",
    "    \"instance_id\" : \"wml_local\",\n",
    "    \"url\": cluster,\n",
    "    \"version\": \"4.8\"\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Use the `write_file` command to write these models to a `model.py` file.\n",
    "\n",
    "This model solves this geometric puzzle:  \n",
    "Start with a pattern of circles placed in rows piled one on top of the other with decreasing numbers in each row to form a triangle. With N circles at the bottom, then N-1 circles in the adjacent row, then N-2 in the next row etc ... until there is just 1 circle in the top row, you must decide which circles to color in, so that the maximum number of circles are colored in. There is however the constraint that no 3 selected circles form a triangle. Hence the center of any circle is considered as a vertex for a potential triangle.\n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "from docplex.mp.model import Model\n",
    "\n",
    "def build_hearts(r, **kwargs):\n",
    "    # initialize the model\n",
    "    mdl = Model('love_hearts_%d' % r, **kwargs)\n",
    "\n",
    "    # the dictionary of decision variables, one variable\n",
    "    # for each circle with i in (1 .. r) as the row and\n",
    "    # j in (1 .. i) as the position within the row    \n",
    "    idx = [(i, j) for i in range(1, r + 1) for j in range(1, i + 1)]\n",
    "    a = mdl.binary_var_dict(idx, name=lambda ij: \"a_%d_%d\" % ij)\n",
    "\n",
    "    # the constraints - enumerate all equilateral triangles\n",
    "    # and prevent any such triangles from being chosen by keeping\n",
    "    # the number of chosen circles with adjacent vertices below 3\n",
    "\n",
    "    # for each row except the last\n",
    "    for i in range(1, r):\n",
    "        # for each position in this row\n",
    "        for j in range(1, i + 1):\n",
    "            # for each triangle of side length (k) with its upper vertex at\n",
    "            # (i, j) and its sides parallel to those of the overall shape\n",
    "            for k in range(1, r - i + 1):\n",
    "                # the sets of 3 points at the same distances clockwise along the\n",
    "                # sides of these triangles form k equilateral triangles\n",
    "                for m in range(k):\n",
    "                    u, v, w = (i + m, j), (i + k, j + m), (i + k - m, j + k - m)\n",
    "                    mdl.add(a[u] + a[v] + a[w] <= 2)\n",
    "\n",
    "    mdl.maximize(mdl.sum(a))\n",
    "    return mdl\n",
    "\n",
    "from docplex.util.environment import get_environment\n",
    "\n",
    "env = get_environment()\n",
    "debug = env.get_parameter(\"MY_DEBUG_FLAG\")\n",
    "if debug is not None:\n",
    "    print(\"DEBUG MODE ON\")\n",
    "    print(debug)\n",
    "else:\n",
    "    print(\"DEBUG MODE OFF\")\n",
    "       \n",
    "\n",
    "mdl = build_hearts(5)\n",
    "mdl.solve(log_output=True if debug is not None else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"model.py\", arcname=\"model.py\", filter=reset)\n",
    "tar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the space ID\n",
    "\n",
    "space_name = \"<space_name>\"\n",
    "\n",
    "space_id = [x['metadata']['id'] for x in client.spaces.get_details()['resources'] if x['entity']['name'] == space_name][0]\n",
    "\n",
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"MyModel\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Loving Hearts\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-docplex_22.1\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_uid_by_name(\"do_22.1\"),\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/wsuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "#model='/home/wsuser/work/model.tar.gz', \n",
    "model_uid = client.repository.get_model_id(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"Loving Hearts Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Loving Hearts Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'num_nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "# print deployment id if needed\n",
    "# print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job  for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "No specific parameter.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    \"solve_parameters\" : {\n",
    "        \"oaas.logAttachmentName\":\"log.txt\",\n",
    "        \"oaas.logTailEnabled\":\"true\",\n",
    "        \"oaas.resultsFormat\": \"XML\"\n",
    "    },\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\".*\\.xml\"\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"log.txt\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print(job_details['entity']['decision_optimization']['solve_state']['solve_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the logs: no parameter is passed to DOcplex so the model is not in debug mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "output_data = job_details['entity']['decision_optimization']['output_data']\n",
    "\n",
    "logs = [line for o in output_data if o['id'] == 'log.txt' for line in io.BytesIO(base64.b64decode(o['content']))]\n",
    "for l in logs:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_log = [l for l in logs if \"DEBUG MODE OFF\" in str(l)]\n",
    "if len(check_log) == 1:\n",
    "    print(\"Solve was ok\")\n",
    "else:\n",
    "    print(\"Something went wrong\")\n",
    "print(check_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run the model and pass it optimization control parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    \"solve_parameters\" : {\n",
    "        \"oaas.logAttachmentName\":\"log.txt\",\n",
    "        \"oaas.logTailEnabled\":\"true\",\n",
    "        \"oaas.resultsFormat\": \"XML\",\n",
    "        \"MY_DEBUG_FLAG\" : \"my debug flag value\"\n",
    "    },\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\".*\\.xml\"\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"log.txt\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print(job_details['entity']['decision_optimization']['solve_state']['solve_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization parameters were passed so DOcplex will be in debug mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "output_data = job_details['entity']['decision_optimization']['output_data']\n",
    "\n",
    "logs = [line for o in output_data if o['id'] == 'log.txt' for line in io.BytesIO(base64.b64decode(o['content']))]\n",
    "for l in logs:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_log = [l for l in logs if \"DEBUG MODE ON\" in str(l)]\n",
    "if len(check_log) == 1:\n",
    "    print(\"Solve was ok\")\n",
    "else:\n",
    "    print(\"Something went wrong\")\n",
    "print(check_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Check out our online documentation <a href=\"https://www.ibm.com/docs/en/cloud-paks/cp-data/4.8.x\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> for more samples, tutorials and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019-2024. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
