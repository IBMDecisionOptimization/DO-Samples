{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a CPLEX export file with MIP starts with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a CPLEX export file with MIP starts, create and monitor jobs, and get solution and logs using the Watson Machine Learning Python Client.\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Install the Watson Machine Learning client API](#setup)\n",
    "2. [Create a client instance](#create)\n",
    "3. [Prepare your model archive](#prepare)\n",
    "4. [Upload your model on Watson Machine Learning](#upload)\n",
    "5. [Create a deployment](#deploy)\n",
    "6. [Create and monitor a job with inline data for your deployed model](#job)\n",
    "7. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client\n",
    "\n",
    "Before you use the sample code in this notebook, you must:\n",
    "\n",
    "- create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning (WML) Service</a> instance. A free plan is offered and information about how to create the instance can be found at <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\"> https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/wml-setup.html.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install WML client API\n",
    "\n",
    "!pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance\n",
    "\n",
    "Use your Watson Machine Learning credentials. You can find information on how to get your API key <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp\">here</a> in the second step of the \"Before you begin\" section and instance's URL <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp\">here</a> in the third step of the \"Procedure\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "wml_credentials = {\n",
    "      \"apikey\": \"<API_key>\",\n",
    "      \"url\": \"<instance_url>\"\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Use the `write_file` command to write these models to a `burger.lp` and `burger.mst` file. \n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile burger.lp\n",
    "\n",
    "\\Problem name: good_burger\n",
    "\n",
    "Maximize\n",
    " obj: 0.250000000000 how_many_beef + 0.150000000000 how_many_bun\n",
    "      + 0.100000000000 how_many_cheese + 0.090000000000 how_many_onions\n",
    "      + 0.030000000000 how_many_pickles + 0.040000000000 how_many_lettuce\n",
    "      + 0.020000000000 how_many_ketchup + 0.040000000000 how_many_tomato\n",
    "Subject To\n",
    " c1: how_many_beef <= 5\n",
    " c2: how_many_beef >= 1\n",
    " c3: how_many_bun <= 5\n",
    " c4: how_many_bun >= 1\n",
    " c5: how_many_cheese <= 5\n",
    " c6: how_many_cheese >= 1\n",
    " c7: how_many_onions <= 5\n",
    " c8: how_many_onions >= 1\n",
    " c9: how_many_pickles <= 5\n",
    " c10: how_many_pickles >= 1\n",
    " c11: how_many_lettuce <= 5\n",
    " c12: how_many_lettuce >= 1\n",
    " c13: how_many_ketchup <= 5\n",
    " c14: how_many_ketchup >= 1\n",
    " c15: how_many_tomato <= 5\n",
    " c16: how_many_tomato >= 1\n",
    " c17: 50 how_many_beef + 330 how_many_bun + 310 how_many_cheese\n",
    "      + how_many_onions + 260 how_many_pickles + 3 how_many_lettuce\n",
    "      + 160 how_many_ketchup + 3 how_many_tomato <= 2999\n",
    " c18: 17 how_many_beef + 9 how_many_bun + 6 how_many_cheese + 2 how_many_onions\n",
    "       <= 149\n",
    " c19: 220 how_many_beef + 260 how_many_bun + 70 how_many_cheese\n",
    "      + 10 how_many_onions + 5 how_many_pickles + 4 how_many_lettuce\n",
    "      + 20 how_many_ketchup + 9 how_many_tomato <= 2999\n",
    " c20: how_many_ketchup - how_many_lettuce = 0\n",
    " c21: how_many_pickles - how_many_tomato = 0\n",
    "\n",
    "Bounds\n",
    "\n",
    "Generals\n",
    " how_many_beef how_many_bun how_many_cheese how_many_onions how_many_pickles\n",
    " how_many_lettuce how_many_ketchup how_many_tomato\n",
    "End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial MIP starts for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile burger.mst\n",
    "\n",
    "<CPLEXSolution version=\"1.0\">\n",
    " <header problemName=\"good_burger\"/>\n",
    " <variables>\n",
    "  <variable name=\"how_many_beef\" index=\"0\" value=\"5\"/>\n",
    "  <variable name=\"how_many_bun\" index=\"1\" value=\"5\"/>\n",
    "  <variable name=\"how_many_cheese\" index=\"2\" value=\"1\"/>\n",
    "  <variable name=\"how_many_onions\" index=\"3\" value=\"5\"/>\n",
    " </variables>\n",
    "</CPLEXSolution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"burger.lp\", arcname=\"burger.lp\", filter=reset)\n",
    "tar.add(\"burger.mst\", arcname=\"burger.mst\", filter=reset)\n",
    "tar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the space ID\n",
    "\n",
    "space_name = \"<space_name>\"\n",
    "\n",
    "space_id = [x['metadata']['id'] for x in client.spaces.get_details()['resources'] if x['entity']['name'] == space_name][0]\n",
    "\n",
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"BurgerProduction\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Burger Production\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-cplex_22.1\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_uid_by_name(\"do_22.1\"),\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/wsuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "#model='/home/wsuser/work/model.tar.gz', \n",
    "model_uid = client.repository.get_model_id(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"BurgerProduction Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"BurgerProduction Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'num_nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "# print deployment id if needed\n",
    "# print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    \"solve_parameters\" : {\n",
    "                \"oaas.logAttachmentName\":\"log.txt\",\n",
    "                \"oaas.logTailEnabled\":\"true\",\n",
    "                \"oaas.resultsFormat\": \"XML\"\n",
    "            },\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.xml\"\n",
    "    },\n",
    "    {\n",
    "        \"id\":\"log.txt\"\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print(job_details['entity']['decision_optimization']['solve_state']['solve_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the MIP Starts were used by the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "output_data = job_details['entity']['decision_optimization']['output_data']\n",
    "\n",
    "starts_in_logs = [line for o in output_data if o['id'] == 'log.txt' for line in io.BytesIO(base64.b64decode(o['content'])) if \"start\" in str(line) ]\n",
    "if len(starts_in_logs) == 0:\n",
    "    print(\"Something went wrong\")\n",
    "elif len(starts_in_logs) == 1:\n",
    "    print(\"MIP starts were provided to the job but engine rejected them\")\n",
    "    print(\"Something went wrong\")\n",
    "elif len(starts_in_logs) == 2:\n",
    "    print(\"MIP starts were provided to the job and were used by the engine\")\n",
    "    for d in starts_in_logs:\n",
    "        print(d)\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Check out our online documentation at <a href=\"https://dataplatform.cloud.ibm.com/docs\" target=\"_blank\" rel=\"noopener noreferrer\">https://dataplatform.cloud.ibm.com/docs</a> for more samples, tutorials and documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "In this sample, the optimization content (LP file + MIP Starts file) was uploaded as Watson Machine Learning model content (call to store_model). When the job is triggered, this model content is used: there is no need for any additional input data.\n",
    "\n",
    "Another possible implementation could be to create an empty Watson Machine Learning model (call store_model with an empty tar.gz file), then when triggering the job, pass the optimization content (LP file + MIP Starts file) as the job input data (client.deployments.DecisionOptimizationMetaNames.INPUT_DATA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019, 2023. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
