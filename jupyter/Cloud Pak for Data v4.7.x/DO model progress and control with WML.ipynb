{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get DO model progress and control solve with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a DOcplex model, publish your own progress kpis and take actions on the progress speed using the Watson Machine Learning Python Client.\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Install the Watson Machine Learning client API](#setup)\n",
    "2. [Create a client instance](#create)\n",
    "3. [Prepare your model archive](#prepare)\n",
    "4. [Upload your model on Watson Machine Learning](#upload)\n",
    "5. [Create a deployment](#deploy)\n",
    "6. [Create and monitor a job with inline data for your deployed model](#job)\n",
    "7. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install WML client API\n",
    "\n",
    "!pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "\n",
    "cluster = \"<your_cluster>\"\n",
    "username = \"<username>\"\n",
    "password = \"<password>\"\n",
    "\n",
    "wml_credentials = {\n",
    "    \"username\": username,\n",
    "    \"password\": password,\n",
    "    \"instance_id\" : \"wml_local\",\n",
    "    \"url\": cluster,\n",
    "    \"version\": \"4.7\"\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Use the `write_file` command to write these models to a `model.py` file.\n",
    "\n",
    "This model is a simple geometric problem that is easily scalable and thus used to demonstrate the engine progress. Any other scalable Mixed Integer Programming model would also work.\n",
    "\n",
    "The model solves this geometric puzzle:  \n",
    "Start with a pattern of circles placed in rows piled one on top of the other with decreasing numbers in each row to form a triangle. With N circles at the bottom, then N-1 circles in the adjacent row, then N-2 in the next row etc ... until there is just 1 circle in the top row, you must decide which circles to color in, so that the maximum number of circles are colored in. There is however the constraint that no 3 selected circles form a triangle. Hence the center of any circle is considered as a vertex for a potential triangle.\n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "from docplex.mp.model import Model\n",
    "from docplex.mp.progress import ProgressListener\n",
    "from docplex.util.environment import get_environment\n",
    "\n",
    "# You use a standard simple listener to track progress info and publish it.\n",
    "# You could use another more complex listener to follow the engine, its internal progress, ...\n",
    "# To keep it simple: you will publish the gap and best bound and keep a history.\n",
    "class MyProgressListener(ProgressListener):\n",
    "    def notify_progress(self, progress_data):\n",
    "        bound = progress_data.best_bound\n",
    "        gap = progress_data.mip_gap\n",
    "                \n",
    "        sd = {'MY_BEST_BOUND': bound,'MY_MIP_GAP': gap}\n",
    "        \n",
    "        #print(sd)\n",
    "        get_environment().update_solve_details(sd)\n",
    "\n",
    "\n",
    "\n",
    "def build_hearts(r, **kwargs):\n",
    "    # initialize the model\n",
    "    mdl = Model('love_hearts_%d' % r, **kwargs)\n",
    "    mdl.parameters.timelimit = 180\n",
    "    mdl.context.solver.auto_publish = False\n",
    "    mdl.add_progress_listener(MyProgressListener())\n",
    "\n",
    "    # the dictionary of decision variables, one variable\n",
    "    # for each circle with i in (1 .. r) as the row and\n",
    "    # j in (1 .. i) as the position within the row    \n",
    "    idx = [(i, j) for i in range(1, r + 1) for j in range(1, i + 1)]\n",
    "    a = mdl.binary_var_dict(idx, name=lambda ij: \"a_%d_%d\" % ij)\n",
    "\n",
    "    # the constraints - enumerate all equilateral triangles\n",
    "    # and prevent any such triangles from being chosen by keeping\n",
    "    # the number of chosen circles with adjacent vertices below 3\n",
    "\n",
    "    # for each row except the last\n",
    "    for i in range(1, r):\n",
    "        # for each position in this row\n",
    "        for j in range(1, i + 1):\n",
    "            # for each triangle of side length (k) with its upper vertex at\n",
    "            # (i, j) and its sides parallel to those of the overall shape\n",
    "            for k in range(1, r - i + 1):\n",
    "                # the sets of 3 points at the same distances clockwise along the\n",
    "                # sides of these triangles form k equilateral triangles\n",
    "                for m in range(k):\n",
    "                    u, v, w = (i + m, j), (i + k, j + m), (i + k - m, j + k - m)\n",
    "                    mdl.add(a[u] + a[v] + a[w] <= 2)\n",
    "\n",
    "    mdl.maximize(mdl.sum(a))\n",
    "    return mdl\n",
    "\n",
    "from docplex.util.environment import get_environment\n",
    "       \n",
    "\n",
    "mdl = build_hearts(11)\n",
    "mdl.solve(log_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"model.py\", arcname=\"model.py\", filter=reset)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the space ID\n",
    "\n",
    "space_name = \"<space_name>\"\n",
    "\n",
    "space_id = [x['metadata']['id'] for x in client.spaces.get_details()['resources'] if x['entity']['name'] == space_name][0]\n",
    "\n",
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"MyModel\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Loving Hearts\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-docplex_22.1\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_uid_by_name(\"do_22.1\"),\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/wsuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "#model='/home/wsuser/work/model.tar.gz', \n",
    "model_uid = client.repository.get_model_id(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"Loving Hearts Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Loving Hearts Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'num_nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "# print deployment id if needed\n",
    "# print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job  for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "No specific parameter.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    \"solve_parameters\" : {\n",
    "        \"oaas.logAttachmentName\":\"log.txt\",\n",
    "        \"oaas.logTailEnabled\":\"true\",\n",
    "        \"oaas.resultsFormat\": \"XML\"\n",
    "    },\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\".*\\.xml\"\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"log.txt\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started.\n",
    "\n",
    "Follow the CPLEX progress, and stop the job if the engine does not converge fast enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "manual_stop = False\n",
    "gap_history = None\n",
    "bestobj_history = None\n",
    "no_progress = 0\n",
    "while no_progress < 10 and manual_stop is False and job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    state = job_details['entity']['decision_optimization']['status']['state']\n",
    "    if state == \"running\":\n",
    "        details = job_details['entity']['decision_optimization']['solve_state']['details']\n",
    "        if 'MY_MIP_GAP' in details:\n",
    "            gap = float(details['MY_MIP_GAP'])\n",
    "            bestobj = float(details['MY_BEST_BOUND'])\n",
    "\n",
    "            msg = \"gap = {0}%, best obj = {1}\".format(gap*100, bestobj)\n",
    "            print(msg)\n",
    "\n",
    "            if gap_history is not None:\n",
    "                if float(gap) == float(gap_history):\n",
    "                    print(\"No progress: {0}/{1}% gap and {2}/{3} bestobj\".format(gap_history, gap, bestobj_history, bestobj))\n",
    "                    no_progress+=1\n",
    "                elif 100*(float(gap_history) - float(gap)) <= 0.1:\n",
    "                    manual_stop = True\n",
    "                    print(\"Stopping as the gap is not converging fast enough: {0}/{1}% gap and {2}/{3} bestobj\".format(gap_history, gap, bestobj_history, bestobj))\n",
    "                    no_progress = 0\n",
    "                else:\n",
    "                    print(\"converging well with {0}\".format(float(gap_history) - float(gap)))\n",
    "                    no_progress = 0\n",
    "            bestobj_history = bestobj\n",
    "            gap_history = gap\n",
    "        else:\n",
    "            print(state)\n",
    "    else:\n",
    "        print(state)\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "if manual_stop is False:\n",
    "    if no_progress < 10:\n",
    "        print(\"No manual stop was triggered\")\n",
    "    else:\n",
    "        print(\"Stopping the solve as the progress is too slow\")\n",
    "        client.deployments.delete_job(job_uid)\n",
    "else:\n",
    "    client.deployments.delete_job(job_uid)\n",
    "#print(job_details['entity']['decision_optimization']['solve_state']['solve_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Check out our online documentation <a href=\"https://www.ibm.com/docs/en/cloud-paks/cp-data/4.7.x\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> for more samples, tutorials and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019, 2024. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
