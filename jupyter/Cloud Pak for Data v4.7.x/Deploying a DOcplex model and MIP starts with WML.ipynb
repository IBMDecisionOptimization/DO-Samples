{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a CPLEX export file with MIP starts with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a CPLEX export file with MIP starts, create and monitor jobs, and get solution and logs using the Watson Machine Learning Python Client.\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Install the Watson Machine Learning client API](#setup)\n",
    "2. [Create a client instance](#create)\n",
    "3. [Prepare your model archive](#prepare)\n",
    "4. [Upload your model on Watson Machine Learning](#upload)\n",
    "5. [Create a deployment](#deploy)\n",
    "6. [Create and monitor a job with inline data for your deployed model](#job)\n",
    "7. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install WML client API\n",
    "\n",
    "!pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "\n",
    "cluster = \"<your_cluster>\"\n",
    "username = \"<username>\"\n",
    "password = \"<password>\"\n",
    "\n",
    "wml_credentials = {\n",
    "\"username\": username,\n",
    "\"password\": password,\n",
    "\"instance_id\" : \"wml_local\",\n",
    "\"url\": cluster,\n",
    "\"version\": \"4.7\"\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Use the `write_file` command to write these models to a `burger.py` and `burger.mst` file. \n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to use the docplex.util.environment get_input_stream method to get access to the MIP start file from the docplex python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile burger.py\n",
    "\n",
    "import os\n",
    "from docplex.mp.model import Model\n",
    "from docplex.util.environment import get_environment\n",
    "\n",
    "def apply_mip_starts(mdl):\n",
    "    env = get_environment()\n",
    "    with env.get_input_stream(\"burger.mst\") as in_stream:\n",
    "        path = os.path.realpath(in_stream.name)\n",
    "        mdl.read_mip_starts(path)\n",
    "\n",
    "def build_good_burger(**kwargs):\n",
    "    mdl = Model(\"good_burger\", **kwargs)\n",
    "\n",
    "    items = ['beef', 'bun', 'cheese', 'onions', 'pickles', 'lettuce', 'ketchup', 'tomato']\n",
    "    item_price = [0.25, 0.15, 0.1, 0.09, 0.03, 0.04, 0.02, 0.04]\n",
    "    item_sodium = [50, 330, 310, 1, 260, 3, 160, 3]\n",
    "    item_fat = [17, 9, 6, 2, 0, 0, 0, 0]\n",
    "    item_calories = [220, 260, 70, 10, 5, 4, 20, 9]\n",
    "\n",
    "    item_vars = mdl.integer_var_dict(items, name=\"how_many\")\n",
    "\n",
    "    for i in range(len(items)):\n",
    "        mdl.add_constraint(item_vars[items[i]] <= 5)\n",
    "        mdl.add_constraint(item_vars[items[i]] >= 1)\n",
    "\n",
    "    mdl.add_constraint(mdl.sum(item_vars[items[h]] * item_sodium[h] for h in range(len(items))) <= 3000 - 1)\n",
    "    mdl.add_constraint(mdl.sum(item_vars[items[h]] * item_fat[h] for h in range(len(items))) <= 150 - 1)\n",
    "    mdl.add_constraint(mdl.sum(item_vars[items[h]] * item_calories[h] for h in range(len(items))) <= 3000 - 1)\n",
    "\n",
    "    mdl.add_constraint(item_vars['ketchup'] == item_vars['lettuce'])\n",
    "    mdl.add_constraint(item_vars['pickles'] == item_vars['tomato'])\n",
    "\n",
    "    total_price = mdl.sum(item_vars[items[h]] * item_price[h] for h in range(len(items)))\n",
    "    mdl.maximize(total_price)\n",
    "\n",
    "    mdl.print_information()\n",
    "    return mdl\n",
    "\n",
    "mdl = build_good_burger()\n",
    "apply_mip_starts(mdl)\n",
    "s = mdl.solve(log_output=True)\n",
    "if not s:\n",
    "    print(\"BURGER model fails\")\n",
    "else:\n",
    "    print('The price of the most expensive burger is ${}'.format(mdl.objective_value))\n",
    "    #mdl.print_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial MIP starts for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile burger.mst\n",
    "\n",
    "<CPLEXSolution version=\"1.0\">\n",
    " <header problemName=\"good_burger\"/>\n",
    " <variables>\n",
    "  <variable name=\"how_many_beef\" index=\"0\" value=\"5\"/>\n",
    "  <variable name=\"how_many_bun\" index=\"1\" value=\"5\"/>\n",
    "  <variable name=\"how_many_cheese\" index=\"2\" value=\"1\"/>\n",
    "  <variable name=\"how_many_onions\" index=\"3\" value=\"5\"/>\n",
    " </variables>\n",
    "</CPLEXSolution>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"burger.py\", arcname=\"burger.py\", filter=reset)\n",
    "tar.add(\"burger.mst\", arcname=\"burger.mst\", filter=reset)\n",
    "tar.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the space ID\n",
    "\n",
    "space_name = \"<space_name>\"\n",
    "\n",
    "space_id = [x['metadata']['id'] for x in client.spaces.get_details()['resources'] if x['entity']['name'] == space_name][0]\n",
    "\n",
    "client.set.default_space(space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"BurgerProduction\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Burger Production\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-docplex_22.1\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_uid_by_name(\"do_22.1\"),\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/wsuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "#model='/home/wsuser/work/model.tar.gz', \n",
    "model_uid = client.repository.get_model_id(model_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"BurgerProduction Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"BurgerProduction Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'num_nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "# print deployment id if needed\n",
    "# print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    \"solve_parameters\" : {\n",
    "                \"oaas.logAttachmentName\":\"log.txt\",\n",
    "                \"oaas.logTailEnabled\":\"true\",\n",
    "                \"oaas.resultsFormat\": \"XML\"\n",
    "            },\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.xml\"\n",
    "    },\n",
    "    {\n",
    "        \"id\":\"log.txt\"\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print(job_details['entity']['decision_optimization']['solve_state']['solve_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the MIP Starts were used by the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "output_data = job_details['entity']['decision_optimization']['output_data']\n",
    "\n",
    "starts_in_logs = [line for o in output_data if o['id'] == 'log.txt' for line in io.BytesIO(base64.b64decode(o['content'])) if \"start\" in str(line) ]\n",
    "if len(starts_in_logs) == 0:\n",
    "    print(\"Something went wrong\")\n",
    "elif len(starts_in_logs) == 1:\n",
    "    print(\"MIP starts were provided to the job but engine rejected them\")\n",
    "    print(\"Something went wrong\")\n",
    "elif len(starts_in_logs) == 2:\n",
    "    print(\"MIP starts were provided to the job and were used by the engine\")\n",
    "    for d in starts_in_logs:\n",
    "        print(d)\n",
    "else:\n",
    "    print(\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Check out our online documentation <a href=\"https://www.ibm.com/docs/en/cloud-paks/cp-data/4.7.x\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> for more samples, tutorials and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "In this sample, the optimization content (Python file + MIP Starts file) was uploaded as Watson Machine Learning model content (call to store_model). When the job is triggered, this model content is used: there is no need for any additional input data.\n",
    "\n",
    "Another possible implementation could be to create an empty Watson Machine Learning model (call store_model with an empty tar.gz file), then when triggering the job, pass the optimization content (Python file + MIP Starts file) as the job input data (client.deployments.DecisionOptimizationMetaNames.INPUT_DATA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019, 2023. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
